{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Using [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as our graph state\n",
    "* Using [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) in graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) to our chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So what field of study would you like to talk about today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Riya\n",
      "\n",
      "I would really like to look into bird-watching\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, any specfic bird you're interested in?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Riya\n",
      "\n",
      "I want to learn about countries that have a native caique population \n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So what field of study would you like to talk about today?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"I would really like to look into bird-watching\",name=\"Riya\"))\n",
    "messages.append(AIMessage(content=f\"Great, any specfic bird you're interested in?\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about countries that have a native caique population \", name=\"Riya\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) can use a sequence of message as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://python.langchain.com/v0.2/docs/concepts/#chat-models) to choose from! Let's work with OpenAI. \n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc371ba-cd7f-4586-9052-ae2f25e4e1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"C:/Users/Lenovo/Documents/code/mat496/.env\", override=True) #path to my env folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    temperature=0.7,\n",
    ")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, that's a fun and specific topic! Caiques are certainly charismatic birds. Just to clarify, are you asking about countries where caiques naturally occur, as in their *native* range, or countries where they might be kept as pets but are not native? I'm going to assume you mean their native range.\\n\\nBased on that, the countries with native caique populations are primarily in **South America**. Specifically:\\n\\n*   **Brazil:** This is a major part of their range. You'll find different caique species in various regions of Brazil.\\n*   **Colombia:** Some caique species extend into parts of Colombia.\\n*   **Ecuador:** Similar to Colombia, some species' ranges include parts of Ecuador.\\n*   **Peru:** Again, some caique species are found in certain regions of Peru.\\n*   **Venezuela:** Caiques can be found in Venezuela as well.\\n*   **Guyana:** Part of their range extends to Guyana\\n*   **Suriname:** Part of their range extends to Suriname\\n*   **French Guiana:** Part of their range extends to French Guiana\\n*   **Bolivia:** Some caique species extend into parts of Bolivia.\\n\\n**Important Considerations:**\\n\\n*   **Species Differentiation:** There are two main species of caique: the White-bellied Caique and the Black-headed Caique. Their ranges overlap in some areas, but they also have distinct distributions. Knowing which species you're interested in will help narrow down the specific countries and regions.\\n*   **Habitat:** Caiques typically inhabit tropical rainforests, humid woodlands, and nearby areas. Their presence within a country depends on the availability of suitable habitat.\\n*   **Conservation Status:** It's worth noting that habitat loss and the pet trade can impact wild caique populations, so understanding their conservation status is important.\\n\\nDo you have a particular species of caique in mind, or a specific region within South America that you're interested in? Knowing that would allow me to provide more detailed information.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--cf7ed8fd-b629-4f21-9be2-88ae985197b9-0', usage_metadata={'input_tokens': 49, 'output_tokens': 421, 'total_tokens': 470, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []},\n",
       " 'finish_reason': 'STOP',\n",
       " 'model_name': 'gemini-2.0-flash',\n",
       " 'safety_ratings': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) and [tool calling interface](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {},
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47bd9ae-b5c9-4b7d-b964-dffacbe89c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def divide(a: float, b: float) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "    Args:\n",
    "        a: numerator\n",
    "        b: denominator\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        return \"Error: Cannot divide by zero\"\n",
    "    return a / b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add a and b.\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract b from a.\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a - b\n",
    "\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time.\n",
    "    No arguments needed.\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now()\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather for a location.\n",
    "    Args:\n",
    "        location: city name or location \n",
    "    \"\"\"\n",
    "    import requests\n",
    "    \n",
    "    # Using Open-Meteo API \n",
    "    \n",
    "    geocoding_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={location}&count=1&language=en&format=json\"\n",
    "    \n",
    "    try:\n",
    "        geo_response = requests.get(geocoding_url)\n",
    "        geo_data = geo_response.json()\n",
    "        \n",
    "        if not geo_data.get(\"results\"):\n",
    "            return f\"Location '{location}' not found\"\n",
    "        \n",
    "        lat = geo_data[\"results\"][0][\"latitude\"]\n",
    "        lon = geo_data[\"results\"][0][\"longitude\"]\n",
    "        city_name = geo_data[\"results\"][0][\"name\"]\n",
    "        \n",
    "        # Get weather data\n",
    "        weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current=temperature_2m,weather_code&temperature_unit=celsius\"\n",
    "        weather_response = requests.get(weather_url)\n",
    "        weather_data = weather_response.json()\n",
    "        \n",
    "        temp = weather_data[\"current\"][\"temperature_2m\"]\n",
    "        \n",
    "        return f\"Current weather in {city_name}: {temp}Â°C\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error getting weather: {str(e)}\"\n",
    "\n",
    "# Bind all tools to the LLM\n",
    "llm_with_tools = llm.bind_tools([multiply, divide, add, subtract, get_current_time, get_weather])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Riya\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'b': 3, 'a': 2},\n",
       "  'id': 'fceb37b9-90c3-4054-9eef-925830033e77',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d34349d2-03dc-4b2e-8a27-7d1c5eed6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 45+64\", name=\"Riya\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c350ffe-f6fc-482e-a509-aca149120775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'b': 64, 'a': 45},\n",
       "  'id': '6083d74d-3378-4196-99d2-48704cdef2e2',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63624814-fda5-4239-bba7-c399be555af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 23-65\", name=\"Riya\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37e54fb3-373e-48b8-807d-e34df9ea3f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'subtract',\n",
       "  'args': {'b': 65, 'a': 23},\n",
       "  'id': '5d693b15-50e2-4cf0-ae7c-40026e7546ef',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7dee97b-74fe-4420-9237-23794faeeaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 45 divided by 5\", name=\"Riya\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8868dba-2358-43f9-94c3-935ffb434f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'divide',\n",
       "  'args': {'b': 5, 'a': 45},\n",
       "  'id': 'bc95013e-5450-422a-a259-14d1bc1b3d16',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b965b99a-49b7-45d7-98ce-2f34e4e172df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is the weather in new york?\", name=\"Riya\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8da1898-5722-4b14-8956-3ee320930a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'location': 'new york'},\n",
       "  'id': '5ed42e18-9263-4607-9079-78099e7276e8',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {},
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior `messages` value.\n",
    " \n",
    "As our graph runs, we want to **append** messages to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) to address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='ce2efe9d-08a8-466f-a727-280e359cd2c8'),\n",
       " HumanMessage(content=\"I'm looking for information on bird-watching.\", additional_kwargs={}, response_metadata={}, name='Riya', id='e1491e84-c194-45ae-8a59-f55240bc80cd'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='8e127daa-243b-40a3-872a-0955e1a027fb')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on bird-watching.\", name=\"Riya\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (32436784-f8d6-4ac8-8b14-ae4dd18c1230)\n",
      " Call ID: 32436784-f8d6-4ac8-8b14-ae4dd18c1230\n",
      "  Args:\n",
      "    b: 3\n",
      "    a: 2\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12dc9af1-6d28-4dea-8b4b-e81be37d0f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Whats the weather in delhi?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (f74bb9f9-0d4b-43aa-a0f3-0e11a93a363e)\n",
      " Call ID: f74bb9f9-0d4b-43aa-a0f3-0e11a93a363e\n",
      "  Args:\n",
      "    location: delhi\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Whats the weather in delhi?\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "568c9f4b-7b3f-44bd-ba9b-6be6df62a096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Whats the time right now?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_current_time (f5b5cc31-349c-4d45-a9f8-b6f65645eb83)\n",
      " Call ID: f5b5cc31-349c-4d45-a9f8-b6f65645eb83\n",
      "  Args:\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Whats the time right now?\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fbae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
